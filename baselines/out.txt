{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_mean': {}, 'custom_metrics': {}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_metric_batches_dropped': 0, 'info': {'min_exploration': 1.0, 'max_exploration': 1.0, 'num_target_updates': 0, 'num_steps_trained': 0, 'num_steps_sampled': 1000, 'sample_time_ms': 598.867, 'replay_time_ms': nan, 'grad_time_ms': nan, 'update_time_ms': 0.005, 'opt_peak_throughput': 0.0, 'opt_samples': nan, 'learner': {}}, 'timesteps_this_iter': 1000, 'done': False, 'timesteps_total': 1000, 'episodes_total': 0, 'training_iteration': 1, 'experiment_id': 'c51652f2a5ec455da2b070b365cb7362', 'date': '2019-07-24_01-58-46', 'timestamp': 1563947926, 'time_this_iter_s': 160.2243037223816, 'time_total_s': 160.2243037223816, 'pid': 8271, 'hostname': 'Shreyass-MacBook-Pro.local', 'node_ip': '10.0.0.162', 'config': {'monitor': False, 'log_level': 'INFO', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'use_eager': False, 'log_sys_usage': True, 'model': {'conv_filters': [[12, 64, 1]], 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 64, 'grayscale': False, 'zero_mean': True, 'custom_preprocessor': None, 'custom_model': None, 'custom_options': {}}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'env_config': {'args': {'frame_skip': 4, 'gray_scale': False, 'frame_stack': 4, 'disable_action_prior': True, 'logging_level': 20, 'monitor': True, 'seed': 42, 'outdir': './output'}, 'test': False}, 'env': 'MineRLNavigateDense-v0', 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 6.25e-05, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_config': {'exploration_fraction': 0, 'exploration_final_eps': 0}, 'num_workers': 0, 'num_gpus': 0, 'num_cpus_per_worker': 0, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'num_envs_per_worker': 1, 'sample_batch_size': 10, 'train_batch_size': 2, 'batch_mode': 'truncate_episodes', 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': True, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'num_atoms': 51, 'v_min': -10.0, 'v_max': 10.0, 'noisy': True, 'sigma0': 0.5, 'dueling': True, 'double_q': True, 'hiddens': [256], 'n_step': 10, 'schedule_max_timesteps': 100000, 'exploration_fraction': 0.1, 'exploration_final_eps': 0.02, 'target_network_update_freq': 10000, 'soft_q': False, 'softmax_temp': 1.0, 'parameter_noise': False, 'buffer_size': 4, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'beta_annealing_fraction': 0.2, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'lr_schedule': None, 'adam_epsilon': 0.00015, 'grad_norm_clipping': 40, 'learning_starts': 1000, 'per_worker_exploration': False, 'worker_side_prioritization': False}, 'time_since_restore': 160.2243037223816, 'timesteps_since_restore': 1000, 'iterations_since_restore': 1, 'num_healthy_workers': 0}
> /anaconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/optimizers/replay_buffer.py(164)_sample_proportional()
-> mass = random.random() * self._it_sum.sum(0, len(self._storage))
(Pdb) --KeyboardInterrupt--
(Pdb) --KeyboardInterrupt--
(Pdb) --KeyboardInterrupt--
(Pdb) --KeyboardInterrupt--
(Pdb) --KeyboardInterrupt--
(Pdb) --KeyboardInterrupt--
(Pdb) 